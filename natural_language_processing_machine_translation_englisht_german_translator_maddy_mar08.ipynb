{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaddyBasu/CapstoneAIML/blob/main/natural_language_processing_machine_translation_englisht_german_translator_maddy_mar08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center> NATURAL LANGUAGE PROCESSING: ENGLISH - GERMAN TRANSLATOR </center></h1>"
      ],
      "metadata": {
        "id": "cNOyz-mYZuXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authors:** Bhagawan Das Armani, Gunasekaran Venkatesan, Madhuman Basu, Sanjay R, Vinayak Hampiholi, Vipin Nair"
      ],
      "metadata": {
        "id": "45QrFkhCaWps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions:** (To be removed at the time of submission).\n",
        "- Use your name, date-time and action in the comment that helps in tracking the changes.\n",
        "- The shared directory is MachineTranslation https://drive.google.com/drive/folders/1mpeQDxowVB45zRKwrjSk8LipxvpQOpWY?usp=drive_link\n",
        "- Machine Learning datasets from https://olympus.mygreatlearning.com/courses/110092/modules/items/6688876?pb_id=17305 is placed in the directory MachineTranslation/DataSet\n",
        "- I have also downloaded the datasets from https://statmt.org/wmt14/translation-task.html and placed the directories in the MachineTranslation/DataSet/"
      ],
      "metadata": {
        "id": "sWkXsZPOVPC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name = 'link0'> INDEX </a>"
      ],
      "metadata": {
        "id": "R-9fVsZfagFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <a href = #link0> INDEX </a>\n",
        "- <a href = #link1> PROBLEM STATEMENT </a>\n",
        "    - <a href = #link11> DOMAIN </a>\n",
        "    - <a href = #link12> CONTEXT </a>\n",
        "    - <a href = #link13> DATA DESCRIPTION </a>\n",
        "    - <a href = #link14> PROJECT OBJECTIVE </a>\n",
        "    - <a href = #link15> IMPORT LIBRARIES </a>\n",
        "- <a href = #link2> 1. PROJECT TASK: MILESTONE 1 </a>\n",
        "    - <a href = #link21> STEP 1: IMPORT AND MERGE THREE DATASETS </a>\n",
        "        - <a href = #link211> STEP 1.1: IMPORT EUROPARL DATASET </a>\n",
        "        - <a href = #link212> STEP 1.2: IMPORT COMMONCRAWL DATASET </a>\n",
        "        - <a href = #link213> STEP 1.3: IMPORT NEWSCOMMENTARY DATASET </a>\n",
        "    - <a href = #link22> STEP 2: DATA CLEANSING </a>\n",
        "    - <a href = #link23> STEP 3: NLP PRE-PROCESSING </a>\n",
        "    - <a href = #link24> STEP 4: DESIGN, TRAIN AND TEST SIMPLE RNN AND LSTM MODELS </a>\n",
        "    - <a href = #link25> STEP 5: INTERIM REPORT </a>\n",
        "- <a href = #link3> 2. PROJECT TASK: MILESTONE 2 </a>\n",
        "    - <a href = #link31> STEP 1: DESIGN, TRAIN AND TEST RNN AND LSTM MODELS WITH EMBEDDINGS </a>\n",
        "    - <a href = #link32> STEP 2: DESIGN, TRAIN AND TEST BIDIRECTIONAL RNN AND LSTM MODELS </a>\n",
        "    - <a href = #link33> STEP 3: DESIGN, TRAIN AND TEST ENCODER - DECODER RNN AND LSTM MODELS </a>\n",
        "    - <a href = #link34> STEP 4: CHOOSE THE BEST PERFORMING MODEL AND PICKLE IT </a>\n",
        "    - <a href = #link35> FINAL REPORT </a>\n",
        "- <a href = #link4> 3. PROJECT TASK: MILESTONE 3 </a>\n",
        "    - <a href = #link41> DESIGN A CLICKABLE UI BASED TRANSLATION INTERFACE </a>"
      ],
      "metadata": {
        "id": "p8Tx-jUKa3t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name = 'link1'> PROBLEM STATEMENT </a>"
      ],
      "metadata": {
        "id": "fmFZa4uvlEC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link11'> DOMAIN </a>"
      ],
      "metadata": {
        "id": "THSd3khTlKHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MACHINE TRANSLATION"
      ],
      "metadata": {
        "id": "BC6dJhZbl4jN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link12'> CONTEXT </a>"
      ],
      "metadata": {
        "id": "-TEjkGf3lP8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Translation is the automated translation of source material into another language without human intervention.The database comes fromACL2014 Ninth workshop on Statistical Machine Translation. This workshop mainly focusses on language translation between European language pairs. The idea behind the workshop is to provide the ability for two parties to communicate and exchange the ideas from different countries"
      ],
      "metadata": {
        "id": "AH55VErDl7SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link13'> DATA DESCRIPTION </a>"
      ],
      "metadata": {
        "id": "-Dk6omDBlSrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The  database  is  basically  sentences  in  German/English  of  various  events.  Three  datasets  are  obtained  from  Statistical  Machine  Translation workshop. Either the dataset can be downloaded from the link or can be used from the shared files. Three datasets are,\n",
        "- <a href ='https://statmt.org/wmt13/training-parallel-europarl-v7.tgz'> Europarl v7 </a>\n",
        "- <a href = 'https://statmt.org/wmt13/training-parallel-commoncrawl.tgz'> Common Crawl corpus </a>\n",
        "- <a href = 'https://statmt.org/wmt14/training-parallel-nc-v9.tgz'> News Commentary </a>\n",
        "\n",
        "Link to download the dataset: https://statmt.org/wmt14/translation-task.html"
      ],
      "metadata": {
        "id": "UmYat7Evl-j7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link14'> PROJECT OBJECTIVE </a>"
      ],
      "metadata": {
        "id": "lGyXBLWqlXuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design a Machine Translation model that can be used to translate sentences from German language to English language or vice-versa."
      ],
      "metadata": {
        "id": "TVBxWcHtnLQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link11'> IMPORT LIBRARIES </a>"
      ],
      "metadata": {
        "id": "iWxG2l--lcDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Import warnings library to make warnings not displayed\n",
        "import warnings\n",
        "\n",
        "# Set the warning filters to ignore the warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "lgq2QqdAUdhn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Import google drive package\n",
        "from google.colab import drive\n",
        "\n",
        "# mount the google drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csuL6UiWaUpt",
        "outputId": "8fc420c1-4e99-4f0f-928c-64bb8b347a96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Import the IPython library to display the output of a code block as markdown\n",
        "import IPython\n",
        "\n",
        "# Include the display and Markdown functions from IPython\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Display the version of IPython\n",
        "display(Markdown(\"**Observations:**\\n- IPython Version: {}\".format(IPython.__version__)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "576r0C6tVAtj",
        "outputId": "bc6be3d4-af93-44d6-8174-ef5edfbc6759"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**\n- IPython Version: 7.34.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Import numpy library\n",
        "import numpy\n",
        "\n",
        "# Display the version of numpy\n",
        "display(Markdown(\"**Observations:**\\n- numpy version: {}\".format(numpy.__version__)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "80bR-QaSZs-k",
        "outputId": "4719669e-8c84-410c-c5d7-88f5ab46f80f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**\n- numpy version: 1.26.4"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Import numpy library\n",
        "import pandas as pd\n",
        "\n",
        "# Display the version of numpy\n",
        "display(Markdown(\"**Observations:**\\n- pandas version: {}\".format(pd.__version__)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uLxRGm74axeK",
        "outputId": "94fbbeb0-71dc-4c09-f7ab-a898044255ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**\n- pandas version: 2.2.2"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Create a function to load data from a file\n",
        "def load_data(filepath, language):\n",
        "\n",
        "    # Open the file in read mode\n",
        "    with open(filepath, \"r\", encoding = \"utf-8\") as f:\n",
        "\n",
        "        # Load the file content\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Create a datafraome and return the dataframe\n",
        "    return pd.DataFrame({\"text\": lines, \"language\": language})"
      ],
      "metadata": {
        "id": "hkJjkofNa3LJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7bZloyBdkeJj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name = 'link2'> PROJECT TASK:MILESTONE 1 </a>"
      ],
      "metadata": {
        "id": "i3eiWP2yhiP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link21'> STEP 1: IMPORT AND MERGE THREE DATASETS </a>"
      ],
      "metadata": {
        "id": "KmRBxe-TieYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name = 'link211'> STEP 1.1: IMPORT EUROPARL DATASET  </a>"
      ],
      "metadata": {
        "id": "Gdr8HtMESsS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Identify the difference between the downloaded datasets for europarl-v7\n",
        "!diff /content/drive/MyDrive/MachineTranslation/DataSet/europarl-v7_de_en.txt /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-europarl-v7/europarl-v7.de-en.de\n",
        "!diff /content/drive/MyDrive/MachineTranslation/DataSet/europarl-v7_en_de.txt /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-europarl-v7/europarl-v7.de-en.en"
      ],
      "metadata": {
        "id": "IyCESKeZYGQT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- The datafiles for europarl-v7 is same for both datasets."
      ],
      "metadata": {
        "id": "VN_cd4G0v46b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Identify the differences between the downloaded datasets for commoncrawl\n",
        "!diff /content/drive/MyDrive/MachineTranslation/DataSet/commoncrawl_de_en.txt /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-commoncrawl/commoncrawl.de-en.de\n",
        "!diff /content/drive/MyDrive/MachineTranslation/DataSet/commoncrawl_en_de.txt /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-commoncrawl/commoncrawl.de-en.en"
      ],
      "metadata": {
        "id": "0zd93ouewP0l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- The datafiles for commoncrawl is same for both datasets."
      ],
      "metadata": {
        "id": "Kn21aK1Zw8rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Identify the differences between the downloaded datasets for news_commmentary-v9\n",
        "!diff /content/drive/MyDrive/MachineTranslation/DataSet/news-commentary-v9_de_en.txt /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-nc-v9/news-commentary-v9.de-en.de\n",
        "!diff /content/drive/MyDrive/MachineTranslation/DataSet/news-commentary-v9_en_de.txt /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-nc-v9/news-commentary-v9.de-en.en"
      ],
      "metadata": {
        "id": "k3zjYkUSw686"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- The datafiles for newxcommentary-v9 is same for both datasets."
      ],
      "metadata": {
        "id": "VIsZfDH2xeX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Comment on the dataloading activities\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Set the file path to access europarl-v7.de-en.de from https://statmt.org/wmt14/translation-task.html\n",
        "europarl_de_path = \"/content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-europarl-v7/europarl-v7.de-en.de\"\n",
        "\n",
        "# Initiate a try block to capture the error while loading the data europarl-v7.de-en.de\n",
        "try:\n",
        "    # Load the file europarl-v7.de-en.de into europarl_de\n",
        "    europarl_de = load_data(europarl_de_path, \"de\")\n",
        "\n",
        "    # Display the success message\n",
        "    display(Markdown(\"- File {} loaded successfully.\".format(europarl_de_path)))\n",
        "\n",
        "# Catch any generic exception\n",
        "except:\n",
        "\n",
        "    # Display the error message\n",
        "    display(Markdown(\"- Encountered the error while loading the file {}.\".format(europarl_de_path)))\n",
        "\n",
        "# Set the file path to access europarl-v7.de-en.en from https://statmt.org/wmt14/translation-task.html\n",
        "europarl_en_path = \"/content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-europarl-v7/europarl-v7.de-en.en\"\n",
        "\n",
        "# Initiate a try block to catpure the error while loading the data europarl-v7.de-en.en\n",
        "try:\n",
        "\n",
        "    # Load the file europarl-v7.de-en.en\n",
        "    europarl_en = load_data(europarl_en_path, \"en\")\n",
        "\n",
        "    # Display the success message\n",
        "    display(Markdown(\"- File {} loaded successfully.\".format(europarl_en_path)))\n",
        "\n",
        "# Catch any generic exception\n",
        "except:\n",
        "\n",
        "    # Display the error message\n",
        "    display(Markdown(\"- Encountered the error while loading the file {}.\".format(europarl_en_path)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "MBJx5SCsTAPt",
        "outputId": "f17fda05-f2f4-4b18-b896-012bfea4618a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- File /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-europarl-v7/europarl-v7.de-en.de loaded successfully."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- File /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-europarl-v7/europarl-v7.de-en.en loaded successfully."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name = 'link212'> STEP 1.2: IMPORT COMMONCRAWL DATASET  </a>"
      ],
      "metadata": {
        "id": "zP6PTVCITGo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Comment on the dataloading activities\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Set the file path to access commoncrawl.de-en.de from https://statmt.org/wmt14/translation-task.html\n",
        "commoncrawl_de_path = \"/content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-commoncrawl/commoncrawl.de-en.de\"\n",
        "\n",
        "# Initiate a try block to capture the error while loading the data commoncrawl.de-en.de\n",
        "try:\n",
        "\n",
        "    # Load the file commoncrawl.de-en.de into commoncrawl_de\n",
        "    commoncrawl_de = load_data(commoncrawl_de_path, \"de\")\n",
        "\n",
        "    # Display the success message\n",
        "    display(Markdown(\"- File {} loaded successfully.\".format(commoncrawl_de_path)))\n",
        "\n",
        "# Catch any generic exception\n",
        "except:\n",
        "\n",
        "    # Display the error message\n",
        "    display(Markdown(\"- Encountered the error while loading the file {}.\".format(commoncrawl_de_path)))\n",
        "\n",
        "# Set the file path to access commoncrawl.de-en.en from https://statmt.org/wmt14/translation-task.html\n",
        "commoncrawl_en_path = \"/content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-commoncrawl/commoncrawl.de-en.en\"\n",
        "\n",
        "# Initiate a try block to capture the error while loading the data commoncrawl.de-en.en\n",
        "try:\n",
        "\n",
        "    # Load the file commoncrawl.de-en.en into commoncrawl_en\n",
        "    commoncrawl_en = load_data(commoncrawl_en_path, \"en\")\n",
        "\n",
        "    # Display the success message\n",
        "    display(Markdown(\"- File {} loaded successfully.\".format(commoncrawl_en_path)))\n",
        "\n",
        "# Catch any generic exception\n",
        "except:\n",
        "\n",
        "    # Display the error message\n",
        "    display(Markdown(\"- Encountered the error while loading the file {}.\".format(commoncrawl_en_path)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "HwoK4nMET8rh",
        "outputId": "1c9bc7a0-3a9f-41b1-85f8-977938cc3ea0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- File /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-commoncrawl/commoncrawl.de-en.de loaded successfully."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- File /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-commoncrawl/commoncrawl.de-en.en loaded successfully."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name = 'link213'> STEP 1.3: IMPORT NEWSCOMMENTARY DATASET  </a>"
      ],
      "metadata": {
        "id": "N9LfoVB-ULNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Feb 23.\n",
        "# Comment on the dataloading activities\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Set the file path to access news-commentary-v9.de-en.de from https://statmt.org/wmt14/translation-task.html\n",
        "newscommentary_de_path = \"/content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-nc-v9/news-commentary-v9.de-en.de\"\n",
        "\n",
        "# Initiate a try block to capture the error while loading the data news-commentary-v9.de-en.de\n",
        "try:\n",
        "\n",
        "    # Load the file news-commentary-v9.de-en.de into newscommentary_de\n",
        "    newscommentary_de = load_data(newscommentary_de_path, \"de\")\n",
        "\n",
        "    # Display the success message\n",
        "    display(Markdown(\"- File {} loaded successfully.\".format(newscommentary_de_path)))\n",
        "\n",
        "# Catch any generic exception\n",
        "except:\n",
        "\n",
        "    # Display the error message\n",
        "    display(Markdown(\"- nEncountered the error while loading the file {}.\".format(newscommentary_de_path)))\n",
        "\n",
        "# Set the file path to access news-commentary-v9.de-en.en from https://statmt.org/wmt14/translation-task.html\n",
        "newscommentary_en_path = \"/content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-nc-v9/news-commentary-v9.de-en.en\"\n",
        "\n",
        "# Initiate a try block to catpure the error while loading the data news-commentary-v9.de-en.en\n",
        "try:\n",
        "\n",
        "    # Load the file news-commentary-v9.de-en.en\n",
        "    newscommentary_en = load_data(newscommentary_en_path, \"en\")\n",
        "\n",
        "    # Display the success message\n",
        "    display(Markdown(\"- File {} loaded successfully.\".format(newscommentary_en_path)))\n",
        "\n",
        "# Catch any generic exception\n",
        "except:\n",
        "\n",
        "    # Display the error message\n",
        "    display(Markdown(\"- Encountered the error while loading the file {}.\".format(newscommentary_en_path)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Glw96rzBUUMO",
        "outputId": "ce7710b5-effe-40bb-ac13-9402a628cfe0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- File /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-nc-v9/news-commentary-v9.de-en.de loaded successfully."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- File /content/drive/MyDrive/MachineTranslation/DataSet/training-parallel-nc-v9/news-commentary-v9.de-en.en loaded successfully."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 4.\n",
        "\n",
        "# Compare the number of rows in the dataframes europarl_de and europarl_en\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Display the number of rows in the dataframe europarl_de\n",
        "display(Markdown(\"- Number of rows in the dataframe europarl_de: {}\".format(europarl_de.shape[0])))\n",
        "\n",
        "# Display the number of rows in the dataframe europarl_en\n",
        "display(Markdown(\"- Number of rows in the dataframe europarl_en: {}\".format(europarl_en.shape[0])))\n",
        "\n",
        "# Compare the numbers and display the observations\n",
        "if europarl_de.shape[0] == europarl_en.shape[0]:\n",
        "\n",
        "    # If the rows are same then print the same\n",
        "    display(Markdown(\"- The number of rows in the dataframes europarl_de and europarl_en are same.\"))\n",
        "\n",
        "else:\n",
        "\n",
        "    # If the rows are different then print the same\n",
        "    display(Markdown(\"- The number of rows in the dataframes europarl_de and europarl_en are not same.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "2Yf2phu-xDYC",
        "outputId": "2b435b2c-b323-4f5d-e1f2-10eda1bf8016"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe europarl_de: 1920209"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe europarl_en: 1920209"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- The number of rows in the dataframes europarl_de and europarl_en are same."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 4.\n",
        "\n",
        "# Compare the number of rows in the dataframes commoncrawl_de and commoncrawl_en\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Display the number of rows in the dataframe commoncrawl_de\n",
        "display(Markdown(\"- Number of rows in the dataframe commoncrawl_de: {}\".format(commoncrawl_de.shape[0])))\n",
        "\n",
        "# Display the number of rows in the dataframe commoncrawl_en\n",
        "display(Markdown(\"- Number of rows in the dataframe commoncrawl_en: {}\".format(commoncrawl_en.shape[0])))\n",
        "\n",
        "# Compare the numbers and display the observations\n",
        "if commoncrawl_de.shape[0] == commoncrawl_en.shape[0]:\n",
        "\n",
        "    # If the rows are same then print the same\n",
        "    display(Markdown(\"- The number of rows in the dataframes commoncrawl_de and commoncrawl_en are same.\"))\n",
        "\n",
        "else:\n",
        "\n",
        "    # If the rows are different then print the same\n",
        "    display(Markdown(\"- The number of rows in the dataframes commoncrawl_de and commoncrawl_en are not same.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "zfpSnzyu2dcq",
        "outputId": "06db45d5-48cc-431e-fb40-f7320526697c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe commoncrawl_de: 2399123"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe commoncrawl_en: 2399123"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- The number of rows in the dataframes commoncrawl_de and commoncrawl_en are same."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 4.\n",
        "\n",
        "# Compare the number of rows in the dataframes newscommentary_de and newscommentary_en\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Display the number of rows in the dataframe newscommentary_de\n",
        "display(Markdown(\"- Number of rows in the dataframe newscommentary_de: {}\".format(newscommentary_de.shape[0])))\n",
        "\n",
        "# Display the number of rows in the dataframe newscommentary_en\n",
        "display(Markdown(\"- Number of rows in the dataframe newscommentary_en: {}\".format(newscommentary_en.shape[0])))\n",
        "\n",
        "# Compare the numbers and display the observations\n",
        "if newscommentary_de.shape[0] == newscommentary_en.shape[0]:\n",
        "\n",
        "    # If the rows are same then print the same\n",
        "    display(Markdown(\"- The number of rows in the dataframes newscommentary_de and newscommentary_en are same.\"))\n",
        "\n",
        "else:\n",
        "\n",
        "    # If the rows are different then print the same\n",
        "    display(Markdown(\"- The number of rows in the dataframes newscommentary_de and newscommentary_en are not same.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "voMTeVWO9ewp",
        "outputId": "c511538a-e878-4d8f-c5d3-baeff98dae03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe newscommentary_de: 201854"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe newscommentary_en: 201995"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- The number of rows in the dataframes newscommentary_de and newscommentary_en are not same."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 7.\n",
        "\n",
        "# Prepare a dataframe that has the columns de_text and en_text in which de_text is taken from german datafiles and en_text is taken from english datafiles\n",
        "translation_dataset = pd.DataFrame({\"de_text\": europarl_de[\"text\"] + commoncrawl_de[\"text\"], \"en_text\": europarl_en[\"text\"] + commoncrawl_en[\"text\"]})\n",
        "\n",
        "# Print the first 10 rows\n",
        "translation_dataset.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "tXTXGGECkqui",
        "outputId": "8df5076f-5293-4599-92a6-818ddf49e531"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             de_text  \\\n",
              "0  Wiederaufnahme der Sitzungsperiode\\niron cemen...   \n",
              "1  Ich erkläre die am Freitag, dem 17. Dezember u...   \n",
              "2  Wie Sie feststellen konnten, ist der gefürchte...   \n",
              "3  Im Parlament besteht der Wunsch nach einer Aus...   \n",
              "4  Heute möchte ich Sie bitten - das ist auch der...   \n",
              "5  Ich bitte Sie, sich zu einer Schweigeminute zu...   \n",
              "6  (Das Parlament erhebt sich zu einer Schweigemi...   \n",
              "7  Frau Präsidentin, zur Geschäftsordnung.\\nACDSe...   \n",
              "8  Wie Sie sicher aus der Presse und dem Fernsehe...   \n",
              "9  Zu den Attentatsopfern, die es in jüngster Zei...   \n",
              "\n",
              "                                             en_text  \n",
              "0  Resumption of the session\\niron cement is a re...  \n",
              "1  I declare resumed the session of the European ...  \n",
              "2  Although, as you will have seen, the dreaded '...  \n",
              "3  You have requested a debate on this subject in...  \n",
              "4  In the meantime, I should like to observe a mi...  \n",
              "5  Please rise, then, for this minute' s silence....  \n",
              "6  (The House rose and observed a minute' s silen...  \n",
              "7  Madam President, on a point of order.\\nTransla...  \n",
              "8  You will be aware from the press and televisio...  \n",
              "9  One of the people assassinated very recently i...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f04015e1-7d29-437b-8fa0-dd7d314aabf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>de_text</th>\n",
              "      <th>en_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wiederaufnahme der Sitzungsperiode\\niron cemen...</td>\n",
              "      <td>Resumption of the session\\niron cement is a re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ich erkläre die am Freitag, dem 17. Dezember u...</td>\n",
              "      <td>I declare resumed the session of the European ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wie Sie feststellen konnten, ist der gefürchte...</td>\n",
              "      <td>Although, as you will have seen, the dreaded '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Im Parlament besteht der Wunsch nach einer Aus...</td>\n",
              "      <td>You have requested a debate on this subject in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Heute möchte ich Sie bitten - das ist auch der...</td>\n",
              "      <td>In the meantime, I should like to observe a mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ich bitte Sie, sich zu einer Schweigeminute zu...</td>\n",
              "      <td>Please rise, then, for this minute' s silence....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(Das Parlament erhebt sich zu einer Schweigemi...</td>\n",
              "      <td>(The House rose and observed a minute' s silen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Frau Präsidentin, zur Geschäftsordnung.\\nACDSe...</td>\n",
              "      <td>Madam President, on a point of order.\\nTransla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Wie Sie sicher aus der Presse und dem Fernsehe...</td>\n",
              "      <td>You will be aware from the press and televisio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Zu den Attentatsopfern, die es in jüngster Zei...</td>\n",
              "      <td>One of the people assassinated very recently i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f04015e1-7d29-437b-8fa0-dd7d314aabf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f04015e1-7d29-437b-8fa0-dd7d314aabf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f04015e1-7d29-437b-8fa0-dd7d314aabf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db4aa545-dd0b-43c7-a607-d1f363fa246c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db4aa545-dd0b-43c7-a607-d1f363fa246c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db4aa545-dd0b-43c7-a607-d1f363fa246c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "translation_dataset"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 7.\n",
        "\n",
        "# Check the unique number of rows in the each column to ensure that the lines do match.\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Display the number of unique rows in the column de_text\n",
        "display(Markdown(\"- Number of rows in the column de_text: {}\".format(len(translation_dataset[\"de_text\"]))))\n",
        "\n",
        "# Display the number of unique rows in the column en_text\n",
        "display(Markdown(\"- Number of rows in the column en_text: {}\".format(len(translation_dataset[\"en_text\"]))))\n",
        "\n",
        "# Print whether the number of rows is same or different\n",
        "if len(translation_dataset[\"de_text\"]) == len(translation_dataset[\"en_text\"]):\n",
        "\n",
        "    # If the rows are same then print the same\n",
        "    display(Markdown(\"- The number of rows in the columns de_text and en_text are same.\"))\n",
        "\n",
        "# Else print the observation\n",
        "else:\n",
        "\n",
        "    # If the rows are different then print the same\n",
        "    display(Markdown(\"- The number of rows in the columns de_text and en_text are not same.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "sVSzfCJ6qqss",
        "outputId": "29e5aa09-e4ae-4eab-9eb8-589e333cccaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the column de_text: 2399123"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the column en_text: 2399123"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- The number of rows in the columns de_text and en_text are same."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link22'> STEP 2: DATA CLEANSING </a>"
      ],
      "metadata": {
        "id": "HERW9N3-infp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 7.\n",
        "\n",
        "# Look for null values and print the total null values\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Display the number of null values in the dataframe translation_dataset\n",
        "display(Markdown(\"- Number of null values in the dataframe translation_dataset: {}\".format(translation_dataset.isnull().sum().sum())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MD7glNao838O",
        "outputId": "791b278d-8677-4c83-989c-9716016bdb6d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of null values in the dataframe translation_dataset: 957828"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This rubric is added by Vinayak Hampiholi on Mar 7.\n",
        "\n",
        "# Remove the null values from the dataset.\n",
        "translation_dataset_final = translation_dataset.dropna()\n",
        "\n",
        "# Print the total number of rows in the dataset after dropping the null values\n",
        "display(Markdown(\"**Observations:**\"))\n",
        "\n",
        "# Display the number of rows in the dataframe translation_dataset\n",
        "display(Markdown(\"- Number of rows in the dataframe translation_dataset: {}\".format(len(translation_dataset_final))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FQDazJWh-gAh",
        "outputId": "f3517717-d4f0-420c-feee-a7c4da511a55"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Observations:**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- Number of rows in the dataframe translation_dataset: 1920209"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link23'> STEP 3: NLP PRE-PROCESSING </a>"
      ],
      "metadata": {
        "id": "Hz5DbkZyiu57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the required NLTK data resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to both German and English text columns\n",
        "translation_dataset_final['de_text'] = translation_dataset_final['de_text'].apply(preprocess_text)\n",
        "translation_dataset_final['en_text'] = translation_dataset_final['en_text'].apply(preprocess_text)\n",
        "\n",
        "# Select 20,000 samples for initial model training\n",
        "translation_dataset_sample = translation_dataset_final.sample(n=20000, random_state=42)\n",
        "\n",
        "# Display the first few rows of the preprocessed dataset\n",
        "print(translation_dataset_sample.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9121_doU9x6",
        "outputId": "8a8678b5-5502-4617-cfc7-7858031a9a9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   de_text  \\\n",
            "1304218  falls es legal ist dann brauchen wir keine deb...   \n",
            "1430939  14 weitere makrofinanzhilfe für georgien entde...   \n",
            "798963   diese forderung verlief im sande zum einen wei...   \n",
            "343558   so funktioniert der rechtsstaat und lord bethe...   \n",
            "326455   wir sind daher durch die weigerung des rates d...   \n",
            "\n",
            "                                                   en_text  \n",
            "1304218  if it is legal we do not need a debate simply ...  \n",
            "1430939  14 further macrofinancial assistance for georg...  \n",
            "798963   the request came to nothing firstly because th...  \n",
            "343558   that is how the judicial system works and lord...  \n",
            "326455   the councils refusal to make the charter of fu...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The preprocessing step would take long due to the large size of the dataset and the complexity of the operations being performed.\n",
        "\n",
        "To speed up the process, we will use parallel processing to apply the preprocessing function to the dataset. This will allow us to utilize multiple CPU cores and reduce the overall processing time.\n"
      ],
      "metadata": {
        "id": "iCRCPdSafEn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Download the required NLTK data resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def parallel_apply(data, func, num_processes):\n",
        "    with Pool(num_processes) as pool:\n",
        "        result = pool.map(func, data)\n",
        "    return result\n",
        "\n",
        "# Apply preprocessing to both German and English text columns using parallel processing\n",
        "num_processes = 4  # Adjust the number of processes based on your system's capabilities\n",
        "translation_dataset_final['de_text'] = parallel_apply(translation_dataset_final['de_text'], preprocess_text, num_processes)\n",
        "translation_dataset_final['en_text'] = parallel_apply(translation_dataset_final['en_text'], preprocess_text, num_processes)\n",
        "\n",
        "# Select 20,000 samples for initial model training\n",
        "translation_dataset_sample = translation_dataset_final.sample(n=20000, random_state=42)\n",
        "\n",
        "# Display the first few rows of the preprocessed dataset\n",
        "print(translation_dataset_sample.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRryOdOmfC_e",
        "outputId": "918d96c3-fe42-4861-f98c-1ad5a2c2f7a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   de_text  \\\n",
            "1304218  falls es legal ist dann brauchen wir keine deb...   \n",
            "1430939  14 weitere makrofinanzhilfe für georgien entde...   \n",
            "798963   diese forderung verlief im sande zum einen wei...   \n",
            "343558   so funktioniert der rechtsstaat und lord bethe...   \n",
            "326455   wir sind daher durch die weigerung des rates d...   \n",
            "\n",
            "                                                   en_text  \n",
            "1304218  if it is legal we do not need a debate simply ...  \n",
            "1430939  14 further macrofinancial assistance for georg...  \n",
            "798963   the request came to nothing firstly because th...  \n",
            "343558   that is how the judicial system works and lord...  \n",
            "326455   the councils refusal to make the charter of fu...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link24'> STEP 4: DESIGN, TRAIN, AND TEST SIMPLE RNN AND LSTM MODELS </a>"
      ],
      "metadata": {
        "id": "kyGcTwKTi6Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(translation_dataset_sample['de_text'] + translation_dataset_sample['en_text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "de_sequences = tokenizer.texts_to_sequences(translation_dataset_sample['de_text'])\n",
        "en_sequences = tokenizer.texts_to_sequences(translation_dataset_sample['en_text'])\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = max(max(len(seq) for seq in de_sequences), max(len(seq) for seq in en_sequences))\n",
        "de_padded = pad_sequences(de_sequences, maxlen=max_sequence_length, padding='post')\n",
        "en_padded = pad_sequences(en_sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(de_padded, en_padded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "caQfYjRNkNuG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model\n",
        "rnn_model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    SimpleRNN(64, return_sequences=True),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the RNN model\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "biBxfpC3kbrn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing new code\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(translation_dataset_sample['de_text'] + translation_dataset_sample['en_text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "de_sequences = tokenizer.texts_to_sequences(translation_dataset_sample['de_text'])\n",
        "en_sequences = tokenizer.texts_to_sequences(translation_dataset_sample['en_text'])\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = max(max(len(seq) for seq in de_sequences), max(len(seq) for seq in en_sequences))\n",
        "de_padded = pad_sequences(de_sequences, maxlen=max_sequence_length, padding='post')\n",
        "en_padded = pad_sequences(en_sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Use a smaller subset of the data for initial training\n",
        "X_train, X_test, y_train, y_test = train_test_split(de_padded[:1000], en_padded[:1000], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nk6-Yg_XoQ9w"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing new code\n",
        "# Define the RNN model with reduced complexity\n",
        "rnn_model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=max_sequence_length),\n",
        "    SimpleRNN(32, return_sequences=True),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the RNN model\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the LSTM model with reduced complexity\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=max_sequence_length),\n",
        "    LSTM(32, return_sequences=True),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CW5mptBTkjeJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing new code\n",
        "# Train the RNN model with reduced batch size\n",
        "rnn_model.fit(X_train, y_train, epochs=5, batch_size=4, validation_data=(X_test, y_test))\n",
        "\n",
        "# Train the LSTM model with reduced batch size\n",
        "lstm_model.fit(X_train, y_train, epochs=5, batch_size=4, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mcjC4BZPokyO",
        "outputId": "9ed3bb61-71e2-40e9-8127-32bc22ff74c2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-35-b10491314a9d>\", line 3, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nOut of memory while trying to allocate 7288550544 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_11747]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b10491314a9d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#testing new code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train the RNN model with reduced batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the LSTM model with reduced batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-35-b10491314a9d>\", line 3, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nOut of memory while trying to allocate 7288550544 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_11747]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link25'> INTERIM REPORT </a>"
      ],
      "metadata": {
        "id": "fvrboig2jG0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name = 'link3'> PROJECT TASK:MILESTONE 2 </a>"
      ],
      "metadata": {
        "id": "Io-M_JDFgmGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link31'> STEP 1: DESIGN, TRAIN AND TEST RNN AND LSTM MODELS WITH EMBEDDINGS </a>"
      ],
      "metadata": {
        "id": "33Y6R6FSgsYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link32'> STEP 2: DESIGN, TRAIN AND TEST BIDIRECTIONAL RNN AND LSTM MODELS </a>"
      ],
      "metadata": {
        "id": "UvhdK0MFg2wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link33'> STEP 3: DESIGN, TRAIN AND TEST ENCODER - DECODER RNN AND LSTM MODELS </a>"
      ],
      "metadata": {
        "id": "uIeXXiKfg81b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link34'> STEP 4: CHOOSE THE BEST PERFORMING MODEL AND PICKLE IT </a>"
      ],
      "metadata": {
        "id": "Ls-JrxFshJtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name = 'link4'> PROJECT TASK: MILESTONE 3 </a>"
      ],
      "metadata": {
        "id": "fgCKITD-gHmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name = 'link41'> STEP 1: DESIGN A CLICKABLE UI BASED TRANSLATION INTERFACE </a>"
      ],
      "metadata": {
        "id": "Vr7f2TpGgZJx"
      }
    }
  ]
}